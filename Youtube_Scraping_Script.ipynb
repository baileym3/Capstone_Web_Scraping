{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "import pandas as pd \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are you looking for?\n",
      "vaccine\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def SearchVid(search):\n",
    "    responce = urllib.request.urlopen('https://www.youtube.com/results?search_query='+search)\n",
    "\n",
    "    soup = BeautifulSoup(responce)    \n",
    "    #divs = soup.find_all(\"div\", { \"class\" : \"video-title\"})\n",
    "    driver.find_element_by_id\n",
    "    print(divs)\n",
    "\n",
    "    for i in divs:\n",
    "        href= i.find('a', href=True)\n",
    "        print(href.text,  \"\\nhttps://www.youtube.com\"+href['href'], '\\n')\n",
    "        with open(SearchString.replace(\"%20\", \"_\")+'.txt', 'a') as writer:\n",
    "            writer.write(\"https://www.youtube.com\"+href['href']+'\\n')\n",
    "\n",
    "print(\"What are you looking for?\")\n",
    "SearchString = input()\n",
    "SearchVid(SearchString.replace(\" \", \"%20\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scraping https://www.youtube.com/\n",
      "Checkpoint 1\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "# open chrome \n",
    "youtube_pages = \"https://www.youtube.com/\"\n",
    "locationOfWebdriver = \"c:\\\\chromedriver_win32\\\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(locationOfWebdriver)\n",
    "driver.get(youtube_pages)\n",
    "time.sleep(10)\n",
    "try:\n",
    "    print(\"=\" * 40)  # Shows in terminal when youtube summary page with search keyword is being scraped\n",
    "    print(\"Scraping \" + youtube_pages)\n",
    "    search = driver.find_element_by_id('search')\n",
    "    search.send_keys(\"vaccine\")    \n",
    "    driver.find_element_by_id('search-icon-legacy').click()\n",
    "    time.sleep(20)    \n",
    "    vtitle = driver.find_elements_by_id('video-title')\n",
    "    subscription = driver.find_elements_by_id('byline')\n",
    "    views = driver.find_elements_by_xpath('//div[@id=\"metadata-line\"]/span[1]')\n",
    "    posted = driver.find_elements_by_xpath('//div[@id=\"metadata-line\"]/span[2]')\n",
    "    \n",
    "    tcount = 0\n",
    "    href = []\n",
    "    title = []\n",
    "    channel = []\n",
    "    numview = []\n",
    "    postdate = []\n",
    "    print('Checkpoint 1')\n",
    "    while tcount < 10:\n",
    "        href.append(vtitle[tcount].get_attribute('href'))\n",
    "        channel.append(subscription[tcount].get_attribute('title'))\n",
    "        title.append(vtitle[tcount].text)\n",
    "        numview.append(views[tcount].text)\n",
    "        postdate.append(posted[tcount].text)  \n",
    "        tcount = tcount +1\n",
    "        \n",
    "    print('Checkpoint 2: Attributes recorded')\n",
    "    # launch top ten extracted links and extract comment details\n",
    "    tcount = 0    \n",
    "    while tcount < 10:  \n",
    "        youtube_dict ={}\n",
    "        # extract comment section of top ten links\n",
    "        url = href[tcount]\n",
    "        print (url)\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        try:\n",
    "            print(\"+\" * 40)  # Shows in terminal when details of a new video is being scraped\n",
    "            print(\"Scraping child links \")\n",
    "            #scroll down to load comments\n",
    "            driver.execute_script('window.scrollTo(0,390);')\n",
    "            time.sleep(15)\n",
    "            #sort by top comments\n",
    "            sort= driver.find_element_by_xpath(\"\"\"//*[@id=\"icon-label\"]\"\"\")\n",
    "            sort.click()\n",
    "            time.sleep(10)\n",
    "            topcomments =driver.find_element_by_xpath(\"\"\"//*[@id=\"menu\"]/a[1]/paper-item/paper-item-body/div[1]\"\"\")\n",
    "            topcomments.click()\n",
    "            time.sleep(10)\n",
    "            # Loads 20 comments , scroll two times to load next set of 40 comments. \n",
    "            for i in range(0,2):\n",
    "                driver.execute_script(\"window.scrollTo(0,Math.max(document.documentElement.scrollHeight,document.body.scrollHeight,document.documentElement.clientHeight))\")\n",
    "                time.sleep(10)\n",
    "            \n",
    "            #count total number of comments and set index to number of comments if less than 50 otherwise set as 50. \n",
    "            totalcomments= len(driver.find_elements_by_xpath(\"\"\"//*[@id=\"content-text\"]\"\"\"))\n",
    "         \n",
    "            if totalcomments < 50:\n",
    "                index= totalcomments\n",
    "            else:\n",
    "                index= 50 \n",
    "                \n",
    "            ccount = 0\n",
    "            while ccount < index: \n",
    "                try:\n",
    "                    comment = driver.find_elements_by_xpath('//*[@id=\"content-text\"]')[ccount].text\n",
    "                except:\n",
    "                    comment = \"\"\n",
    "                try:\n",
    "                    authors = driver.find_elements_by_xpath('//a[@id=\"author-text\"]/span')[ccount].text\n",
    "                except:\n",
    "                    authors = \"\"\n",
    "                try:\n",
    "                    comment_posted = driver.find_elements_by_xpath('//*[@id=\"published-time-text\"]/a')[ccount].text\n",
    "                except:\n",
    "                    comment_posted = \"\"\n",
    "                try:\n",
    "                    replies = driver.find_elements_by_xpath('//*[@id=\"more-text\"]')[ccount].text                    \n",
    "                    if replies ==\"View reply\":\n",
    "                        replies= 1\n",
    "                    else:\n",
    "                        replies =replies.replace(\"View \",\"\")\n",
    "                        replies =replies.replace(\" replies\",\"\")\n",
    "                except:\n",
    "                    replies = \"\"\n",
    "                try:\n",
    "                    upvotes = driver.find_elements_by_xpath('//*[@id=\"vote-count-middle\"]')[ccount].text\n",
    "                except:\n",
    "                    upvotes = \"\"\n",
    "                        \n",
    "                youtube_dict['url'] = href[tcount]\n",
    "                youtube_dict['link_title'] = title[tcount]\n",
    "                youtube_dict['channel'] = channel[tcount]\n",
    "                youtube_dict['no_of_views'] = numview[tcount]\n",
    "                youtube_dict['time_uploaded'] =  postdate[tcount]\n",
    "                youtube_dict['comment'] = comment\n",
    "                youtube_dict['author'] = authors\n",
    "                youtube_dict['comment_posted'] = comment_posted\n",
    "                youtube_dict['no_of_replies'] = replies\n",
    "                youtube_dict['upvotes'] = upvotes\n",
    "                \n",
    "                writer.writerow(youtube_dict.values())\n",
    "                ccount = ccount +1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            driver.close()\n",
    "        tcount = tcount +1 \n",
    "    print(\"Scrapping process Completed\")   \n",
    "    csv_file.close()    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#content = driver.find_element_by_xpath(\\'//*[@id=\"contents\"]\\')\\ncomm=driver.find_element_by_xpath(\\'//div[@class=\"style-scope ytd-item-section-renderer\"]\\')\\ncomm1=comm.find_elements_by_xpath(\\'//yt-formatted-string[@id=\"content-text\"]\\')\\n#print(comm.text)\\nfor element in comm1:\\n    print(comm1.text,end=\\' \\')\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locationOfWebdriver = \"c:\\\\chromedriver_win32\\\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(locationOfWebdriver)\n",
    "\n",
    "url=\"https://www.youtube.com/watch?v=JIfUNEJvCmo\"\n",
    "driver.get(url)\n",
    "wait = WebDriverWait(driver,15)\n",
    "#driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "comments = []\n",
    "\n",
    "for item in range(20): \n",
    "        wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#content-text\"))):\n",
    "        comments.append(comment.text)\n",
    "\"\"\"\n",
    "delay = 3 #number of seconds\n",
    "try:\n",
    "    myElem = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.ID, 'element_id')))\n",
    "    WebDriverWait(driver, timeout).until(element_present)\n",
    "    print (\"Page is ready!\")\n",
    "except TimeoutException:\n",
    "    print(\"Loading took too much time!\")\n",
    "#driver.implicitly_wait(5000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#content = driver.find_element_by_xpath('//*[@id=\"contents\"]')\n",
    "comm=driver.find_element_by_xpath('//div[@class=\"style-scope ytd-item-section-renderer\"]')\n",
    "comm1=comm.find_elements_by_xpath('//yt-formatted-string[@id=\"content-text\"]')\n",
    "#print(comm.text)\n",
    "for element in comm1:\n",
    "    print(comm1.text,end=' ')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>Not gonna lie, watching the play at the 10:00 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>NO  NO it whooooooooo whooooooooo it's the col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>cole train was a character in the original ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>Let me just say individual bullet path.\\nhits ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>Shoutout to Sparton 696 for the format\\n\\n\\nFi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>This game just confirms, Warhammer 40k is made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>Reposted and edited... Odd there is a cat invo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>First :D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>Character \\nName: Clint Von strife (code name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>So glad I found your channel! \\nThere’s buddy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>Please, what is the word Chris used in ~22:13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>Name:Ryan \\nLast Name:Jensen\\nCode Name:-You c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>Check the lure 4 the coal train. He is one bad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>(Repost from Episode 1)\\n\\nFirst Name: Ardenit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>Yes, Cole is apart of the series.\\nA former Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>This is looking a lot better than Chimera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>Name: Antonio \"Castle\" Sachetta\\n\\n\\nAppearanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>(Repost)\\n\\nName: Celestia Mercer\\n\\nAppearanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>Reposting since i REALLY want a character\\n(Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>Reposted and Edited\\nFirst Name: Mike\\n\\nLast ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment\n",
       "103  Not gonna lie, watching the play at the 10:00 ...\n",
       "104  NO  NO it whooooooooo whooooooooo it's the col...\n",
       "105  cole train was a character in the original ser...\n",
       "106  Let me just say individual bullet path.\\nhits ...\n",
       "107  Shoutout to Sparton 696 for the format\\n\\n\\nFi...\n",
       "108  This game just confirms, Warhammer 40k is made...\n",
       "109  Reposted and edited... Odd there is a cat invo...\n",
       "110                                           First :D\n",
       "111  Character \\nName: Clint Von strife (code name ...\n",
       "112  So glad I found your channel! \\nThere’s buddy ...\n",
       "113  Please, what is the word Chris used in ~22:13 ...\n",
       "114  Name:Ryan \\nLast Name:Jensen\\nCode Name:-You c...\n",
       "115  Check the lure 4 the coal train. He is one bad...\n",
       "116  (Repost from Episode 1)\\n\\nFirst Name: Ardenit...\n",
       "117  Yes, Cole is apart of the series.\\nA former Th...\n",
       "118          This is looking a lot better than Chimera\n",
       "119  Name: Antonio \"Castle\" Sachetta\\n\\n\\nAppearanc...\n",
       "120  (Repost)\\n\\nName: Celestia Mercer\\n\\nAppearanc...\n",
       "121  Reposting since i REALLY want a character\\n(Re...\n",
       "122  Reposted and Edited\\nFirst Name: Mike\\n\\nLast ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(comments, columns = ['comment'])\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Character \\nName: Clint Von strife (code name Vanguard)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[111, 'comment']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
